{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2/7/20.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPnC29cbLWgE8hk/HO3Z0NO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tjk168/IS-465-/blob/master/2_7_20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJ9M9H7cG99X",
        "colab_type": "code",
        "outputId": "9260fa98-d3ca-477e-d6f2-62bbe74e3ada",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print('hello world')"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hello world\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyK9R3aSOrDQ",
        "colab_type": "text"
      },
      "source": [
        "This is the start"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kprkhf1HhZA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# Author: Olivier Grisel <olivier.grisel@ensta.org>\n",
        "#         Lars Buitinck\n",
        "#         Chyi-Kwei Yau <chyikwei.yau@gmail.com>\n",
        "# License: BSD 3 clause\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UX307rXJHrTD",
        "colab_type": "text"
      },
      "source": [
        "import some packages: time is python time \n",
        "\n",
        "web mining is mining the text\n",
        "web mining is fun\n",
        "I like this class\n",
        "idf log3/2\n",
        "tf-idf 1/6*log3/2\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ye90Rd_JIYm2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from time import time\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
        "from sklearn.datasets import fetch_20newsgroups"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rU0xULmiKKIq",
        "colab_type": "text"
      },
      "source": [
        "define some variables "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLJv0YT4KOxX",
        "colab_type": "code",
        "outputId": "98cdee61-0ebc-4813-a0f4-842e2b8669b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "n_samples = 2000\n",
        "n_features = 1000\n",
        "n_components = 10\n",
        "n_top_words = 20\n",
        "print(n_samples)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGm4eNacKk4J",
        "colab_type": "text"
      },
      "source": [
        "Define function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFPFisMbKmvA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_top_words(model, feature_names, n_top_words):\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        message = \"Topic #%d: \" % topic_idx\n",
        "        message += \" \".join([feature_names[i]\n",
        "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
        "        print(message)\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCOi9Gc9K9QU",
        "colab_type": "text"
      },
      "source": [
        "# Load the 20 newsgroups dataset and vectorize it. We use a few heuristics\n",
        "# to filter out useless terms early on: the posts are stripped of headers,\n",
        "# footers and quoted replies, and common English words, words occurring in\n",
        "# only one document or in at least 95% of the documents are removed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWjs_4u4LOT7",
        "colab_type": "code",
        "outputId": "1b8e8980-2dc6-4b2e-c075-b4213493a9dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(\"Loading dataset...\")\n",
        "t0 = time()\n",
        "data, _ = fetch_20newsgroups(shuffle=True, random_state=1,\n",
        "                             remove=('headers', 'footers', 'quotes'),\n",
        "                             return_X_y=True)\n",
        "data_samples = data[:n_samples]\n",
        "print(\"done in %0.3fs.\" % (time() - t0))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n",
            "done in 1.900s.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TB5ty8PLsFg",
        "colab_type": "text"
      },
      "source": [
        "# Use tf-idf features for NMF."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNryVPxrLxYv",
        "colab_type": "code",
        "outputId": "eaa58dc3-f739-467d-b4db-58f4eb2997e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(\"Extracting tf-idf features for NMF...\")\n",
        "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2,\n",
        "                                   max_features=n_features,\n",
        "                                   stop_words='english')\n",
        "t0 = time()\n",
        "tfidf = tfidf_vectorizer.fit_transform(data_samples)\n",
        "print(\"done in %0.3fs.\" % (time() - t0))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting tf-idf features for NMF...\n",
            "done in 0.375s.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gUH-fM-MDL_",
        "colab_type": "text"
      },
      "source": [
        "# Use tf (raw term count) features for LDA."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUMvwNYQMG-I",
        "colab_type": "code",
        "outputId": "ae2f8643-be48-4dd6-f12e-837624d7b55c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print(\"Extracting tf features for LDA...\")\n",
        "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2,\n",
        "                                max_features=n_features,\n",
        "                                stop_words='english')\n",
        "t0 = time()\n",
        "tf = tf_vectorizer.fit_transform(data_samples)\n",
        "print(\"done in %0.3fs.\" % (time() - t0))\n",
        "print()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting tf features for LDA...\n",
            "done in 0.379s.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVGGQs2XMQoD",
        "colab_type": "text"
      },
      "source": [
        "# Fit the NMF model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYYfShQ-MS3z",
        "colab_type": "code",
        "outputId": "d60af53a-5c0d-45fd-caad-d72d6d516d1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "print(\"Fitting the NMF model (Frobenius norm) with tf-idf features, \"\n",
        "      \"n_samples=%d and n_features=%d...\"\n",
        "      % (n_samples, n_features))\n",
        "t0 = time()\n",
        "nmf = NMF(n_components=n_components, random_state=1,\n",
        "          alpha=.1, l1_ratio=.5).fit(tfidf)\n",
        "print(\"done in %0.3fs.\" % (time() - t0))\n",
        "\n",
        "print(\"\\nTopics in NMF model (Frobenius norm):\")\n",
        "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
        "print_top_words(nmf, tfidf_feature_names, n_top_words)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting the NMF model (Frobenius norm) with tf-idf features, n_samples=2000 and n_features=1000...\n",
            "done in 0.394s.\n",
            "\n",
            "Topics in NMF model (Frobenius norm):\n",
            "Topic #0: just people don think like know time good make way really say right ve want did ll new use years\n",
            "Topic #1: windows use dos using window program os drivers application help software pc running ms screen files version card code work\n",
            "Topic #2: god jesus bible faith christian christ christians does heaven sin believe lord life church mary atheism belief human love religion\n",
            "Topic #3: thanks know does mail advance hi info interested email anybody looking card help like appreciated information send list video need\n",
            "Topic #4: car cars tires miles 00 new engine insurance price condition oil power speed good 000 brake year models used bought\n",
            "Topic #5: edu soon com send university internet mit ftp mail cc pub article information hope program mac email home contact blood\n",
            "Topic #6: file problem files format win sound ftp pub read save site help image available create copy running memory self version\n",
            "Topic #7: game team games year win play season players nhl runs goal hockey toronto division flyers player defense leafs bad teams\n",
            "Topic #8: drive drives hard disk floppy software card mac computer power scsi controller apple mb 00 pc rom sale problem internal\n",
            "Topic #9: key chip clipper keys encryption government public use secure enforcement phone nsa communications law encrypted security clinton used legal standard\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9mcpvOKNT7m",
        "colab_type": "text"
      },
      "source": [
        "# Fit the NMF model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oVsBWEoNXKF",
        "colab_type": "code",
        "outputId": "a975ec1e-f6af-4881-e01d-216266a73c03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "print(\"Fitting the NMF model (generalized Kullback-Leibler divergence) with \"\n",
        "      \"tf-idf features, n_samples=%d and n_features=%d...\"\n",
        "      % (n_samples, n_features))\n",
        "t0 = time()\n",
        "nmf = NMF(n_components=n_components, random_state=1,\n",
        "          beta_loss='kullback-leibler', solver='mu', max_iter=1000, alpha=.1,\n",
        "          l1_ratio=.5).fit(tfidf)\n",
        "print(\"done in %0.3fs.\" % (time() - t0))\n",
        "\n",
        "print(\"\\nTopics in NMF model (generalized Kullback-Leibler divergence):\")\n",
        "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
        "print_top_words(nmf, tfidf_feature_names, n_top_words)\n",
        "\n"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting the NMF model (generalized Kullback-Leibler divergence) with tf-idf features, n_samples=2000 and n_features=1000...\n",
            "done in 1.571s.\n",
            "\n",
            "Topics in NMF model (generalized Kullback-Leibler divergence):\n",
            "Topic #0: people don just like think did say time make know really right said things way ve course didn question probably\n",
            "Topic #1: windows help thanks using hi looking info video dos pc does anybody ftp appreciated mail know advance available use card\n",
            "Topic #2: god does jesus true book christian bible christians religion faith believe life church christ says know read exist lord people\n",
            "Topic #3: thanks know bike interested mail like new car edu heard just price list email hear want cars thing sounds reply\n",
            "Topic #4: 10 00 sale time power 12 new 15 year 30 offer condition 14 16 model 11 monitor 100 old 25\n",
            "Topic #5: space government number public data states earth security water research nasa general 1993 phone information science technology provide blood internet\n",
            "Topic #6: edu file com program soon try window problem remember files sun send library article mike wrong think code win manager\n",
            "Topic #7: game team year games play win season points world division won players nhl flyers toronto case cubs teams ll record\n",
            "Topic #8: drive think hard software disk drives apple computer mac need scsi card don problem read floppy post cable going ii\n",
            "Topic #9: use good just key chip got like ll way clipper doesn keys don better speed stuff want sure going need\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzpfrgimOTWe",
        "colab_type": "text"
      },
      "source": [
        "LDA Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPSzvrP4OUOG",
        "colab_type": "code",
        "outputId": "0b1c4948-c803-4991-c8d3-ef14f12e4031",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(\"Fitting LDA models with tf features, \"\n",
        "      \"n_samples=%d and n_features=%d...\"\n",
        "      % (n_samples, n_features))\n",
        "lda = LatentDirichletAllocation(n_components=n_components, max_iter=5,\n",
        "                                learning_method='online',\n",
        "                                learning_offset=50.,\n",
        "                                random_state=0)\n",
        "t0 = time()\n",
        "lda.fit(tf)\n",
        "print(\"done in %0.3fs.\" % (time() - t0))\n",
        "\n",
        "print(\"\\nTopics in LDA model:\")\n",
        "tf_feature_names = tf_vectorizer.get_feature_names()\n",
        "print_top_words(lda, tf_feature_names, n_top_words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting LDA models with tf features, n_samples=2000 and n_features=1000...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWDNo4CeB6Ms",
        "colab_type": "text"
      },
      "source": [
        "Homework 2- Analyze the documents you classified"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQe0EIx3Et_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wordlist = data_samples[0].split()\n",
        "BigString = ''.join(BigString)\n",
        "print(BigString)\n",
        "wordfreq = []\n",
        "for w in wordlist:\n",
        "    wordfreq.append(wordlist.count(w))\n",
        "str(list(zip(wordlist, wordfreq)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3GabzH_Lahi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Visualization for Word Frequencies"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxKv04zmN4JK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from os import path\n",
        "from PIL import Image\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvvNmbZcPnes",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Start with one review\n",
        "text = data_samples[0]\n",
        "\n",
        "# create a dn generate a word cloud\n",
        "wordcloud = WordCloud().generate(text)\n",
        "\n",
        "#display the generated image\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}